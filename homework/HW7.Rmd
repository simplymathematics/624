---
title: "Kuhn and Johnson Chapter 7"
author: "simplymathematics"
date: "April 7, 2019"
output: html_document
---


## 7.3
Here we split the data.
```{r, echo = FALSE}
library(mlbench, quietly = TRUE)
library(caret, quietly = TRUE)
library(earth, quietly = TRUE)
set.seed(200)
trainingData <- mlbench.friedman1(200, sd = 1)
df = as.data.frame(trainingData)
head(df)
trainingData$x <- data.frame(trainingData$x)
featurePlot(trainingData$x, trainingData$y)
```
Here I generate the test data.
```{r}
testData <- mlbench.friedman1(5000, sd = 1)
testData$x <- data.frame(testData$x)
```
Here I build a KNN classifier.
```{r}
knnModel <- train(x = trainingData$x, 
                  y = trainingData$y, 
                  method = "knn", preProc =                             c("center", "scale"), 
                  tuneLength = 10)
plot(knnModel$results$RMSE)
```
The minimized RMSE appears to happen around 6 cluster, although 5 and 7 give similar results.

```{r}
mars <- earth(trainingData$x, trainingData$y)
mars
```
Mars selects x1-x6.

## 7.5
Below is the data presented for modelling.
```{r, echo = FALSE}
library(AppliedPredictiveModeling, quietly = TRUE)
library(doParallel, quietly = TRUE)
rCluster <- makePSOCKcluster(6)
registerDoParallel(rCluster)
data(ChemicalManufacturingProcess)
df <- as.data.frame(ChemicalManufacturingProcess)
df
```
Here, I replaced NAs with the mean of the column they are in and center and scaled all the data.
```{r}
na_to_mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
df <- replace(df, TRUE, lapply(df, na_to_mean))
pre <- preProcess(df, method = c("center", "scale"))
data <- predict(pre, df)
data
```
Here, I create my training and test sets as well as label sets.
```{r}
all_indexes = 1:176
training_index = sample(1:176, size = 140)
test_index = setdiff(all_indexes, training_index)
training = data[training_index,]
testing = data[test_index,]
test_labels <- testing['Yield'] 
train_labels <- training['Yield']
features <- training
features['Yield'] <- NULL
```

Below we build a neural net.
```{r}
library(neuralnet, quietly = TRUE)
model1 <- neuralnet(Yield~. , data = training, hidden = c(5,3))
#plot(model1)
tmp <- compute(model1, testing)
pred1 <- tmp$net.result
rmse1 <- sum(((pred1 - test_labels)^2)^.5)
```
Then, we build a knn. Here we find that the optimal cluster size is 3 or 5

```{r}
model2 <- train(x  = features , 
                  y = train_labels$Yield, 
                  method = "knn", preProc =                             c("center", "scale"), 
                  tuneLength = 10)
plot(model2$results$RMSE)
```

Model 3 was a MARS model.
```{r}
model3 <- earth(x  = features , y = train_labels$Yield)
pred3 <- predict(model3, testing)
rmse3 <- sum(((pred3 - test_labels)^2)^.5)
rmse3
```
Below is an SVM, using the polynomial kernel.
```{r}
library(e1071, quietly = TRUE)
labels = list(train_labels)
model4 <- svm(Yield ~ ., data = training, kernel = "polynomial")
pred4 <- predict(model4, testing)
rmse4 <- sum(((pred4 - test_labels)^2)^.5)
rmse4
```
Below we can compare the results of 3 of the models.
```{r}
barplot(c(rmse1, rmse3, rmse4), names.arg = c('NN', 'KNN', 'SVM'), main = "RMSE for Various Models")
```
Since the KNN is a classifier rather than a regressor, it is inappropriate for this data and the RMSE comparator. Both the KNN and NN perform well with the data, but the NN wins slightly.
